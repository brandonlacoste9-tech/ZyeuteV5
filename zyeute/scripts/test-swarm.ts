/**
 * ğŸ Global Hive Pulse - Swarm Verification Test
 * Tests the Multi-Model Orchestration System
 * Verifies model selection and failover logic
 */

import { ollama, selectOllamaModel, checkOllamaHealth, listOllamaModels } from "../backend/ai/ollama-service.js";

async function runGlobalPulse() {
  console.log("\nğŸ ==========================================");
  console.log("ğŸ  GLOBAL HIVE PULSE - SWARM VERIFICATION");
  console.log("ğŸ ==========================================\n");

  // Step 1: Health Check
  console.log("ğŸ“¡ Step 1: Checking Ollama Health...");
  const isHealthy = await checkOllamaHealth();
  if (!isHealthy) {
    console.error("âŒ Ollama service is not available!");
    console.error("   Make sure Ollama is running: ollama serve");
    process.exit(1);
  }
  console.log("âœ… Ollama service is healthy\n");

  // Step 2: List Available Models
  console.log("ğŸ“‹ Step 2: Listing Available Models...");
  const models = await listOllamaModels();
  console.log(`âœ… Found ${models.length} models:\n`);
  models.forEach((model) => {
    console.log(`   â€¢ ${model}`);
  });
  console.log("");

  // Step 3: Test Model Selection Logic
  console.log("ğŸ§  Step 3: Testing Sovereign Routing Logic...\n");

  const testCases = [
    {
      name: "Quebec Culture Content",
      config: { task: "quebec" as const },
      prompt: "Parle-moi de la fÃªte nationale du QuÃ©bec en franÃ§ais quÃ©bÃ©cois.",
      expectedModel: "brandonlacoste9/zyeuteV8:latest",
    },
    {
      name: "Code Generation",
      config: { task: "code" as const },
      prompt: "Optimise cette fonction TypeScript pour gÃ©rer un ledger Piasse: function calculateBalance(transactions: Transaction[]) { ... }",
      expectedModel: "deepseek-v3.1:671b-cloud",
    },
    {
      name: "Speed Priority",
      config: { priority: "speed" as const },
      prompt: "Quick hello! How are you?",
      expectedModel: "gemini-3-flash-preview:cloud",
    },
    {
      name: "Quality Priority",
      config: { priority: "quality" as const },
      prompt: "Explain the economic implications of a decentralized currency system.",
      expectedModel: "gpt-oss:120b-cloud",
    },
    {
      name: "Reasoning Task",
      config: { task: "reasoning" as const },
      prompt: "Analyze the pros and cons of implementing a credit-based economy in a social platform.",
      expectedModel: "deepseek-v3.1:671b-cloud",
    },
    {
      name: "Creative Writing",
      config: { task: "creative" as const },
      prompt: "Write a short story about a beaver named TI-GUY exploring Montreal.",
      expectedModel: "brandonlacoste9/zyeuteV8:latest",
    },
    {
      name: "Local Only",
      config: { requiresLocal: true, priority: "balance" as const },
      prompt: "Explain what makes Quebec culture unique.",
      expectedModel: "llama3.2:latest",
    },
  ];

  let successCount = 0;
  let failCount = 0;

  for (const testCase of testCases) {
    console.log(`\nğŸ¯ Testing: ${testCase.name}`);
    console.log(`   Config:`, JSON.stringify(testCase.config));
    
    const selectedModel = selectOllamaModel(testCase.config);
    console.log(`   ğŸš€ Selected Model: ${selectedModel}`);
    
    if (selectedModel === testCase.expectedModel) {
      console.log(`   âœ… Routing correct!`);
    } else {
      console.log(`   âš ï¸  Expected ${testCase.expectedModel}, got ${selectedModel}`);
    }

    // Test actual generation with failover
    try {
      const start = Date.now();
      console.log(`   â³ Generating response...`);
      
      const response = await ollama.generate(testCase.prompt, {
        model: selectedModel,
        temperature: 0.7,
        max_tokens: 200,
      });
      
      const duration = ((Date.now() - start) / 1000).toFixed(2);
      console.log(`   âœ… Success in ${duration}s`);
      console.log(`   ğŸ“ Preview: ${response.slice(0, 100).replace(/\n/g, " ")}...`);
      
      successCount++;
    } catch (err: any) {
      console.error(`   âŒ Model ${selectedModel} failed: ${err.message}`);
      console.log(`   ğŸ”„ Failover should trigger automatically...`);
      failCount++;
    }
  }

  // Step 4: Summary
  console.log("\n\nğŸ“Š ==========================================");
  console.log("ğŸ“Š  PULSE SUMMARY");
  console.log("ğŸ“Š ==========================================");
  console.log(`âœ… Successful Tests: ${successCount}/${testCases.length}`);
  console.log(`âŒ Failed Tests: ${failCount}/${testCases.length}`);
  console.log(`ğŸ“ˆ Success Rate: ${((successCount / testCases.length) * 100).toFixed(1)}%`);
  
  if (successCount === testCases.length) {
    console.log("\nğŸ‰ THE SWARM IS VERIFIED. READY TO SCALE, BOSS. ğŸğŸ”¥");
  } else {
    console.log("\nâš ï¸  Some models need attention. Check errors above.");
  }
  console.log("");
}

// Run the pulse
runGlobalPulse().catch((error) => {
  console.error("\nâŒ Fatal error during pulse:", error);
  process.exit(1);
});